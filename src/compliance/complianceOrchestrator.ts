// ============================================================
// ASSURE CODE — Compliance Orchestrator
// The main engine. Coordinates RAG retrieval → Gemini draft →
// OpenAI scan → Claude final report.
//
// Claude acts as the FINAL ARBITER: it receives both the draft
// and the scan findings and synthesizes a definitive report.
// This separates the "creative" generation (Gemini) from the
// "critical" analysis (OpenAI) and the "authoritative" output
// (Claude).
// ============================================================

import Anthropic from '@anthropic-ai/sdk';
import { v4 as uuidv4 } from 'uuid';
import { retrieveRegulations } from '../rag/vectorStore';
import { generateDraft } from './draftEngine';
import { scanDraft, requiresHumanReview } from './scannerService';
import {
  SpecificationRequest,
  ComplianceReport,
  DraftSpecification,
  ScanResult,
  RetrievedRegulation,
} from '../types';

const CLAUDE_MODEL = 'claude-sonnet-4-6';

let _client: Anthropic | null = null;

function getClient(): Anthropic {
  if (!_client) {
    if (!process.env.ANTHROPIC_API_KEY) {
      throw new Error('ANTHROPIC_API_KEY is not set in environment variables.');
    }
    _client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });
  }
  return _client;
}

// ============================================================
// CLAUDE: FINAL ARBITRATION PROMPT
// Claude reconciles the draft + scan findings into a coherent
// final specification, patching gaps identified by the scanner.
// ============================================================

function buildArbitrationPrompt(
  request: SpecificationRequest,
  draft: DraftSpecification,
  scanResult: ScanResult,
  regulations: RetrievedRegulation[]
): string {
  return `
You are the Assure Code Compliance Architect — the final authority on whether a technical specification meets regulatory requirements.

A draft specification was generated by a junior architect and reviewed by a hostile auditor. Your job is to:
1. Review the scan findings
2. Amend the draft to address each finding
3. Produce a final, authoritative compliance report

<original_request>
Project: ${request.projectIdea}
Jurisdictions: ${request.jurisdictions.join(', ')}
Frameworks: ${request.frameworks.join(', ')}
</original_request>

<scan_result>
Score: ${scanResult.score.toFixed(2)} / 1.00
Status: ${scanResult.status}
Passed: ${scanResult.passed}
Executive Summary: ${scanResult.executiveSummary}

Findings (${scanResult.findings.length}):
${scanResult.findings.map((f, i) =>
  `${i + 1}. [${f.riskLevel.toUpperCase()}] ${f.issue}
   Regulation: ${f.regulation}
   Gap: ${f.gap}
   Remediation: ${f.remediation}`
).join('\n\n')}
</scan_result>

<draft_specification>
${JSON.stringify(draft, null, 2)}
</draft_specification>

INSTRUCTIONS:
- If there are HIGH risk findings, you MUST amend the relevant sections of the draft to address them.
- For MEDIUM and LOW findings, address them if the fix is straightforward; otherwise document them as accepted risk.
- The developerPrompt field must explicitly mention every high-risk finding and its remediation so developers cannot miss it.
- Do not change sections that are already compliant.
- Maintain the exact same JSON structure as the draft.

Return the amended specification as a JSON object with the EXACT same structure as the draft, plus one additional field:
"arbitrationNotes": [
  { "finding": "<issue>", "action": "amended|accepted_risk|deferred", "amendment": "<what was changed or why it was accepted>" }
]`;
}

// ============================================================
// ORCHESTRATION PIPELINE
// ============================================================

/**
 * Run the full compliance pipeline:
 * 1. Retrieve relevant regulations from pgvector
 * 2. Generate draft spec via Gemini
 * 3. Scan draft via OpenAI
 * 4. Arbitrate and finalize via Claude
 * 5. Return a complete ComplianceReport
 */
export async function runCompliancePipeline(
  request: SpecificationRequest
): Promise<ComplianceReport> {
  const requestId = uuidv4();
  const client = getClient();

  console.log(`\n${'='.repeat(60)}`);
  console.log(`[Orchestrator] Starting pipeline | ID: ${requestId}`);
  console.log(`[Orchestrator] Project: "${request.projectIdea.slice(0, 80)}..."`);
  console.log(`[Orchestrator] Frameworks: ${request.frameworks.join(', ')}`);
  console.log(`[Orchestrator] Jurisdictions: ${request.jurisdictions.join(', ')}`);
  console.log(`${'='.repeat(60)}\n`);

  // ── Step 1: RAG Retrieval ────────────────────────────────
  console.log('[Orchestrator] Step 1/4: RAG retrieval...');
  const regulations = await retrieveRegulations(
    request.projectIdea,
    request.frameworks,
    request.jurisdictions
  );

  if (regulations.length === 0) {
    throw new Error(
      `[Orchestrator] No regulations found for frameworks=${request.frameworks} / jurisdictions=${request.jurisdictions}. ` +
      'Run the ingestion pipeline first: npx ts-node src/rag/ingestion.ts'
    );
  }
  console.log(`[Orchestrator] Retrieved ${regulations.length} regulations.\n`);

  // ── Step 2: Draft Generation (Gemini) ───────────────────
  console.log('[Orchestrator] Step 2/4: Generating draft with Gemini...');
  const draft: DraftSpecification = await generateDraft(request, regulations);
  console.log('[Orchestrator] Draft generated.\n');

  // ── Step 3: Scan (OpenAI) ───────────────────────────────
  console.log('[Orchestrator] Step 3/4: Scanning draft with OpenAI...');
  const scanResult: ScanResult = await scanDraft(draft, regulations);
  console.log(`[Orchestrator] Scan complete. Score: ${scanResult.score.toFixed(2)}\n`);

  // ── Step 4: Final Arbitration (Claude) ──────────────────
  console.log('[Orchestrator] Step 4/4: Claude arbitration...');

  let finalDraft = draft;
  let finalStatus = scanResult.status;

  // Only invoke Claude arbitration if there are findings to address
  if (scanResult.findings.length > 0) {
    const arbitrationPrompt = buildArbitrationPrompt(request, draft, scanResult, regulations);

    const response = await client.messages.create({
      model: CLAUDE_MODEL,
      max_tokens: 8192,
      messages: [{ role: 'user', content: arbitrationPrompt }],
    });

    const rawText = response.content[0].type === 'text' ? response.content[0].text : '';

    try {
      // Strip markdown fences if present
      const cleaned = rawText.replace(/^```(?:json)?\n?/, '').replace(/\n?```$/, '').trim();
      finalDraft = JSON.parse(cleaned);

      // If Claude addressed high-risk findings, upgrade the status
      const highRiskFindings = scanResult.findings.filter(f => f.riskLevel === 'high');
      const allHighRiskAddressed = (finalDraft as any).arbitrationNotes?.filter(
        (n: any) => n.action === 'amended'
      ).length >= highRiskFindings.length;

      if (allHighRiskAddressed && scanResult.score >= 0.7) {
        finalStatus = 'compliant';
      }
    } catch (err) {
      console.warn('[Orchestrator] Claude arbitration response could not be parsed. Using original draft.');
      console.warn('[Orchestrator] Raw response:', rawText.slice(0, 300));
      // Fall back to original draft — do not fail the pipeline
      finalDraft = draft;
    }
  }

  console.log('[Orchestrator] Arbitration complete.\n');

  // ── Assemble Final Report ───────────────────────────────
  const humanReview = requiresHumanReview(scanResult);

  const report: ComplianceReport = {
    requestId,
    projectIdea: request.projectIdea,
    jurisdictions: request.jurisdictions,
    frameworks: request.frameworks,
    retrievedRegulations: regulations,
    draft: finalDraft,
    scanResult,
    finalStatus,
    requiresHumanReview: humanReview,
    completedAt: new Date().toISOString(),
  };

  console.log(`${'='.repeat(60)}`);
  console.log(`[Orchestrator] Pipeline complete.`);
  console.log(`[Orchestrator] Final Status: ${finalStatus}`);
  console.log(`[Orchestrator] Scan Score: ${scanResult.score.toFixed(2)}`);
  console.log(`[Orchestrator] Human Review Required: ${humanReview}`);
  console.log(`${'='.repeat(60)}\n`);

  return report;
}

// ============================================================
// CONVENIENCE: Save report to Supabase audit table
// ============================================================

export async function saveReport(report: ComplianceReport): Promise<void> {
  const { createClient } = await import('@supabase/supabase-js');
  const supabase = createClient(
    process.env.SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!
  );

  const { error } = await supabase.from('compliance_reports').insert({
    request_id: report.requestId,
    project_idea: report.projectIdea,
    jurisdictions: report.jurisdictions,
    frameworks: report.frameworks,
    final_status: report.finalStatus,
    scan_score: report.scanResult.score,
    requires_human_review: report.requiresHumanReview,
    report_json: report,
  });

  if (error) {
    console.error('[Orchestrator] Failed to save report:', error.message);
    // Don't throw — saving to audit log is non-critical
  } else {
    console.log(`[Orchestrator] Report saved to audit log: ${report.requestId}`);
  }
}
